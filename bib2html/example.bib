% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Bittel:2015,
  Title                    = {Pixel-wise Segmentation of Street with Neural Networks},
  Author                   = {Sebastian Bittel AND Vitali Kaiser AND Marvin Teichmann AND Martin Thoma},
  Year                     = {2015},

  Month                    = nov,

  Abstract                 = {Pixel-wise street segmentation of photographs taken from a drivers perspective is important for self-driving cars and can also support other object recognition tasks. A framework called SST was developed to examine the accuracy and execution time of different neural networks. The best neural network achieved an F1-score of 89.5% with a simple feedforward neural network which trained to solve a regression task.},
  Date                     = {2015-11-02},
  Eprint                   = {http://arxiv.org/abs/1511.00513v1},
  Eprintclass              = {cs.CV},
  Eprinttype               = {arxiv},
  Keywords                 = {machine learning; artificial neural networks; classification; supervised learning; MLP; multilayer perceptrons},
  Pdf                      = {http://arxiv.org/pdf/1511.00513v1},
  Url                      = {http://arxiv.org/abs/1511.00513},
  Version                  = {1}
}

@Article{Thoma:2016-creativity,
  Title                    = {Creativity in Machine Learning},
  Author                   = {Martin Thoma},
  Year                     = {2016},

  Month                    = jan,
  Pages                    = {5},

  Abstract                 = {Recent machine learning techniques can be modified to produce creative results. Those results did not exist before; it is not a trivial combination of the data which was fed into the machine learning system. The obtained results come in multiple forms: As images, as text and as audio. 
This paper gives a high level overview of how they are created and gives some examples. It is meant to be a summary of the current work and give people who are new to machine learning some starting points.},
  Date                     = {2016-01-13},
  Eprint                   = {http://arxiv.org/abs/1601.03642v1},
  Eprintclass              = {cs.CV, cs.LG},
  Eprinttype               = {arxiv},
  Pdf                      = {http://arxiv.org/pdf/1601.03642v1},
  Url                      = {http://arxiv.org/abs/1601.03642v1},
  Version                  = {1}
}

@MastersThesis{Thoma:2014-bs,
  Title                    = {On-line {Recognition} of {Handwritten} {Mathematical} {Symbols}},
  Author                   = {Martin Thoma},
  School                   = {Karlsruhe Institute of Technology},
  Year                     = {2014},

  Address                  = {Karlsruhe, Germany},
  Month                    = nov,
  Type                     = {Bachelor’s Thesis},

  Abstract                 = {Finding the name of an unknown symbol is often hard, but writing the symbol is easy. This bachelor's thesis presents multiple systems that use the pen trajectory to classify handwritten symbols. Five preprocessing steps, one data augmentation algorithm, five features and five variants for multilayer Perceptron training were evaluated using 166898 recordings which were collected with two crowdsourcing projects. The evaluation results of these 21 experiments were used to create an optimized recognizer which has a TOP1 error of less than 17.5% and a TOP3 error of 4.0%. This is an improvement of 18.5% for the TOP1 error and 29.7% for the TOP3 error.},
  Keywords                 = {handwriting recognition; on-line; machine learning;
 artificial neural networks; mathematics; classification;
 supervised learning; MLP; multilayer perceptrons; hwrt;
 write-math},
  Pages                    = {58},
  Pdf                      = {http://arxiv.org/pdf/1511.09030v1},
  Url                      = {http://martin-thoma.com/write-math}
}

@Article{Thoma:2014-dycos,
  Title                    = {Über die Klassifizierung von Knoten in dynamischen Netzwerken mit Inhalt},
  Author                   = {Martin Thoma},
  Year                     = {2014},

  Month                    = jan,
  Pages                    = {6},

  Abstract                 = {This paper explains the DYCOS-Algorithm as it was introduced in by Aggarwal and Li in 2011. It operates on graphs whichs nodes are partially labeled and automatically adds missing labels to nodes. To do so, the DYCOS algorithm makes use of the structure of the graph as well as content which is assigned to the node. Aggarwal and Li measured in an experimental analysis that DYCOS adds the missing labels to a Graph with 19396 nodes of which 14814 are labeled and another Graph with 806635 nodes of which 18999 are labeld on one core of an Intel Xeon 2.5 GHz CPU with 32 G RAM within less than a minute. Additionally, extensions of the DYCOS algorithm are proposed. 
----- 
In dieser Arbeit wird der DYCOS-Algorithmus, wie er 2011 von Aggarwal und Li vorgestellt wurde, erkl\"art. Er arbeitet auf Graphen, deren Knoten teilweise mit Beschriftungen versehen sind und erg\"anzt automatisch Beschriftungen f\"ur Knoten, die bisher noch keine Beschriftung haben. Dieser Vorgang wird "Klassifizierung" genannt. Dazu verwendet er die Struktur des Graphen sowie textuelle Informationen, die den Knoten zugeordnet sind. Die von Aggarwal und Li beschriebene experimentelle Analyse ergab, dass er auch auf dynamischen Graphen mit 19396 bzw. 806635 Knoten, von denen nur 14814 bzw. 18999 beschriftet waren, innerhalb von weniger als einer Minute auf einem Kern einer Intel Xeon 2.5 GHz CPU mit 32 G RAM ausgef\"uhrt werden kann. Zus\"atzlich wird die Ver\"offentlichung von Aggarwal und Li kritisch er\"ortert und und es werden m\"ogliche Erweiterungen des DYCOS-Algorithmus vorgeschlagen.},
  Date                     = {2014-01-17},
  Eprint                   = {http://arxiv.org/abs/1512.04469v1},
  Eprintclass              = {cs.LG},
  Eprinttype               = {arxiv},
  Keywords                 = {classification; Klassifizierung},
  Pdf                      = {http://arxiv.org/pdf/1512.04469v1},
  Url                      = {http://arxiv.org/abs/1512.04469v1},
  Version                  = {1}
}

@Article{Thoma:2015-bs-paper,
  Title                    = {On-line Recognition of Handwritten Mathematical Symbols},
  Author                   = {Thoma, Martin and Kilgour, Kevin and St{\"u}ker, Sebastian and Waibel, Alexander},
  Journal                  = {KIT Scientific Working Papers},
  Year                     = {2015},

  Month                    = jun,
  Pages                    = {8},
  Volume                   = {32},

  Doi                      = {10.5445/IR/1000048047},
  ISSN                     = {2194-1629},
  Keywords                 = {handwriting recognition; on-line; machine learning;
 artificial neural networks; mathematics; classification;
 supervised learning; MLP; multilayer perceptrons; hwrt;
 write-math},
  Url                      = {http://digbib.ubka.uni-karlsruhe.de/volltexte/1000048047},
  Urn                      = {http://nbn-resolving.org/urn:nbn:de:swb:90-480476}
}

