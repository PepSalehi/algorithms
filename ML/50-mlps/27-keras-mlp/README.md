## Purpose

Copied from `22-keras-mlp`. Added dropout layers after the two Dense layers and doubled their size.
71.80% is to be beaten.

## Results


```
acc: 71.29%

real    2766,02s
user    4660,64s
sys    425,05s
```

and

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               262400    
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               65792     
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
activation_2 (Activation)    (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 369)               94833     
=================================================================
Total params: 423,025
Trainable params: 423,025
Non-trainable params: 0
_________________________________________________________________
None
16992/16992 [==============================] - 1s 67us/step

acc: 74.11%
```
