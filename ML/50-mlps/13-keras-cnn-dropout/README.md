## Purpose

This is copied from `08-keras-cnn`. Now I double the second last layers nodes
and train for 700 epochs.


## Results

```
Epoch 700/700
151241/151241 [==============================] - 13s 84us/step - loss: 0.4169 - acc: 0.8906 - val_loss: 0.0898 - val_acc: 0.9749

Epoch 00700: val_loss did not improve from 0.06464
16992/16992 [==============================] - 1s 74us/step

acc: 75.92%

real    8930,74s
user    12712,64s
sys    1320,18s

```

Evaluation:

```
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 30, 30, 16)        160
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 15, 15, 16)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 13, 13, 16)        2320
_________________________________________________________________
flatten_1 (Flatten)          (None, 2704)              0
_________________________________________________________________
dense_1 (Dense)              (None, 512)               1384960
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328
_________________________________________________________________
dense_3 (Dense)              (None, 369)               94833
=================================================================
Total params: 1,613,601
Trainable params: 1,613,601
Non-trainable params: 0
_________________________________________________________________
None
16992/16992 [==============================] - 2s 112us/step

acc: 75.95%
```

Performance slightly decreased.
